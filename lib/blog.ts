import fs from 'fs'
import matter from 'gray-matter'
import path from 'path'
import readingTime from 'reading-time'

import { compileMDX } from './compile-mdx'
import { contentCache, getCachedContent } from './content-cache'
import { extractTocHeadings } from './toc'

interface StructuredData {
  '@context': string
  '@type': string
  headline: string
  datePublished: string
  dateModified: string
  description?: string
  image: string
  url: string
}

export type { StructuredData }

export interface BlogPost {
  slug: string
  title: string
  date: string
  tags: string[]
  lastmod?: string
  draft?: boolean
  summary?: string
  images?: string[]
  author?: string
  authors?: string[]
  layout?: string
  bibliography?: string
  canonicalUrl?: string
  categories?: string[]
  type: string
  body: {
    raw: string
    code: string
  }
  readingTime: {
    text: string
    minutes: number
    time: number
    words: number
  }
  path: string
  filePath: string
  toc: Array<{
    value: string
    url: string
    depth: number
  }>
  structuredData: StructuredData
  [key: string]: unknown
}

export interface Author {
  slug: string
  name: string
  avatar?: string
  occupation?: string
  company?: string
  email?: string
  twitter?: string
  linkedin?: string
  github?: string
  layout?: string
  body: {
    raw: string
    code: string
  }
}

const contentDir = path.join(process.cwd(), 'data')
const blogDir = path.join(contentDir, 'blog')
const authorsDir = path.join(contentDir, 'authors')

// è·å–æ‰€æœ‰åšå®¢æ–‡ç«  - ä¼˜åŒ–ç‰ˆæœ¬
export async function getAllBlogPosts(): Promise<BlogPost[]> {
  // æ£€æŸ¥ç¼“å­˜æ˜¯å¦æ–°é²œ
  if (contentCache.isIndexFresh()) {
    const cachedPosts = contentCache.getAllPosts()
    if (cachedPosts.length > 0) {
      // éœ€è¦æ ¹æ®ç¼“å­˜çš„å…ƒæ•°æ®é‡æ–°è¯»å–å®Œæ•´å†…å®¹
      const posts: BlogPost[] = []
      for (const meta of cachedPosts) {
        const post = await getBlogPost(meta.slug)
        if (post) posts.push(post)
      }
      return posts
    }
  }

  const posts: BlogPost[] = []

  async function readDir(dir: string, basePath: string = ''): Promise<void> {
    try {
      const files = fs.readdirSync(dir)

      for (const file of files) {
        const filePath = path.join(dir, file)
        const stat = fs.statSync(filePath)

        if (stat.isDirectory()) {
          await readDir(filePath, path.join(basePath, file))
        } else if (file.endsWith('.mdx') || file.endsWith('.md')) {
          const content = fs.readFileSync(filePath, 'utf-8')
          const { data, content: body } = matter(content)

          // è·³è¿‡è‰ç¨¿
          if (data.draft === true) continue

          // åˆ›å»ºæ­£ç¡®çš„ slugï¼Œä¿æŒå¹´ä»½/æœˆä»½/æ–‡ç« åçš„æ ¼å¼
          const pathParts = basePath.split(path.sep).filter(Boolean)
          let slug = ''
          if (pathParts.length >= 2) {
            if (file === 'index.mdx' || file === 'index.md') {
              slug = pathParts.join('/')
            } else {
              slug = pathParts.join('/') + '/' + file.replace(/\.(mdx?|md)$/, '')
            }
          } else {
            slug = basePath
              ? path.join(basePath, file.replace(/\.(mdx?|md)$/, ''))
              : file.replace(/\.(mdx?|md)$/, '')
          }

          const relativePath = path.relative(blogDir, filePath)
          let urlPath = ''
          if (pathParts.length >= 2) {
            if (file === 'index.mdx' || file === 'index.md') {
              // å¯¹äº index æ–‡ä»¶ï¼Œè·¯å¾„å°±æ˜¯ç›®å½•è·¯å¾„ï¼Œä¸åŒ…å«æ–‡ä»¶å
              urlPath = 'blog/' + pathParts.join('/')
            } else {
              urlPath = 'blog/' + pathParts.join('/') + '/' + file.replace(/\.(mdx?|md)$/, '')
            }
          } else {
            urlPath = basePath
              ? 'blog/' + path.join(basePath, file.replace(/\.(mdx?|md)$/, ''))
              : 'blog/' + file.replace(/\.(mdx?|md)$/, '')
          }

          // é¢„ç¼–è¯‘ MDX å†…å®¹
          const compiledMDX = await compileMDX(body)

          const post: BlogPost = {
            slug: slug.replace(/\\/g, '/'),
            title: data.title || '',
            date: data.date || '',
            tags: data.tags || [],
            lastmod: data.lastmod,
            draft: data.draft || false,
            summary: data.summary || '',
            images: data.images,
            author: data.author || 'default',
            authors: data.authors || ['default'],
            layout: data.layout || 'PostLayout',
            bibliography: data.bibliography,
            canonicalUrl: data.canonicalUrl,
            categories: data.categories || [],
            type: data.type || 'Blog',
            body: {
              raw: body,
              code: compiledMDX,
            },
            readingTime: readingTime(body),
            path: urlPath.replace(/\\/g, '/'),
            filePath: relativePath.replace(/\\/g, '/'),
            toc: extractTocHeadings(body),
            structuredData: {
              '@context': 'https://schema.org',
              '@type': 'BlogPosting',
              headline: data.title,
              datePublished: data.date,
              dateModified: data.lastmod || data.date,
              description: data.summary,
              image: data.images ? data.images[0] : '/static/images/twitter-card.png',
              url: `${process.env.NEXT_PUBLIC_SITE_URL || 'https://www.ygqygq2.com'}/blog/${slug}`,
            },
          }

          posts.push(post)
          // ç¼“å­˜å•ä¸ªæ–‡ç« å…ƒæ•°æ®
          contentCache.setPost(post.slug, post)
        }
      }
    } catch (error) {
      console.error('Error reading directory:', dir, (error as Error).message)
    }
  }

  if (fs.existsSync(blogDir)) {
    await readDir(blogDir)
  }

  // æ›´æ–°ç´¢å¼•ç¼“å­˜
  contentCache.updateIndex()

  return posts.sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime())
}

// å¿«é€Ÿè·å–å•ä¸ªæ–‡ç«  - ä¿®å¤ç‰ˆæœ¬
export async function getBlogPost(slug: string): Promise<BlogPost | null> {
  console.log(`ğŸ” æŸ¥æ‰¾æ–‡ç« : ${slug}`)

  // é¦–å…ˆå°è¯•ä»ç¼“å­˜è·å–å®Œæ•´å†…å®¹
  const cached = getCachedContent(slug)
  if (cached) {
    console.log(`âœ… ä»ç¼“å­˜è·å–æ–‡ç« : ${slug}`)
    return cached
  }

  // å¦‚æœç¼“å­˜æ²¡æœ‰ï¼Œå…ˆç¡®ä¿ç´¢å¼•æ˜¯æœ€æ–°çš„
  if (!contentCache.isIndexFresh()) {
    console.log(`ğŸ”„ é‡æ–°åŠ è½½æ–‡ç« ç´¢å¼•`)
    await getAllBlogPosts()
  }

  // ä»ç´¢å¼•ä¸­æŸ¥æ‰¾æ–‡ç« å…ƒæ•°æ®
  const allCachedPosts = contentCache.getAllPosts()
  const postMeta = allCachedPosts.find((p) => p.slug === slug)

  if (!postMeta) {
    console.log(`âŒ æ–‡ç« ä¸å­˜åœ¨: ${slug}`)
    return null
  }

  // ç›´æ¥è¯»å–æ–‡ä»¶å†…å®¹
  try {
    const blogDir = path.join(process.cwd(), 'data', 'blog')
    const possiblePaths = [
      path.join(blogDir, `${slug}.mdx`),
      path.join(blogDir, `${slug}.md`),
      path.join(blogDir, slug, 'index.mdx'),
      path.join(blogDir, slug, 'index.md'),
    ]

    let targetPath = ''
    for (const p of possiblePaths) {
      if (fs.existsSync(p)) {
        targetPath = p
        break
      }
    }

    if (!targetPath) {
      console.log(`âŒ æ–‡ä»¶ä¸å­˜åœ¨: ${slug}ï¼Œå°è¯•è·¯å¾„:`, possiblePaths)
      return null
    }

    console.log(`ğŸ“ æ‰¾åˆ°æ–‡ä»¶: ${targetPath}`)
    const fileContent = fs.readFileSync(targetPath, 'utf-8')
    const { data, content: body } = matter(fileContent)

    if (data.draft === true) {
      console.log(`â­ï¸ è·³è¿‡è‰ç¨¿: ${slug}`)
      return null
    }

    // é¢„ç¼–è¯‘ MDX
    const compiledMDX = await compileMDX(body)

    const post: BlogPost = {
      ...postMeta,
      type: postMeta.type || 'Blog',
      path: postMeta.path || slug.replace(/\\/g, '/'),
      filePath: postMeta.filePath || `${slug}.mdx`,
      body: {
        raw: body,
        code: compiledMDX,
      },
      readingTime: readingTime(body),
      toc: extractTocHeadings(body),
      structuredData: postMeta.structuredData || {
        '@context': 'https://schema.org',
        '@type': 'BlogPosting',
        headline: postMeta.title,
        datePublished: postMeta.date,
        dateModified: postMeta.lastmod || postMeta.date,
        description: postMeta.summary,
        image: postMeta.images?.[0] || '/static/images/twitter-card.png',
        url: `${process.env.NEXT_PUBLIC_SITE_URL || 'https://www.ygqygq2.com'}/blog/${slug}`,
      },
    }

    // ç¼“å­˜å®Œæ•´å†…å®¹
    contentCache.setContent(slug, post)
    console.log(`âœ… æˆåŠŸåŠ è½½æ–‡ç« : ${slug}`)

    return post
  } catch (error) {
    console.error(`âŒ è¯»å–æ–‡ç« å¤±è´¥: ${slug}`, error)
    return null
  }
} // è·å–æ‰€æœ‰ä½œè€…
export async function getAllAuthors(): Promise<Author[]> {
  const authors: Author[] = []

  if (!fs.existsSync(authorsDir)) {
    return authors
  }

  const files = fs.readdirSync(authorsDir)

  for (const file of files) {
    if (file.endsWith('.mdx') || file.endsWith('.md')) {
      const filePath = path.join(authorsDir, file)
      const content = fs.readFileSync(filePath, 'utf-8')
      const { data, content: body } = matter(content)

      const author: Author = {
        slug: file.replace(/\.(mdx?|md)$/, ''),
        name: data.name || '',
        avatar: data.avatar,
        occupation: data.occupation,
        company: data.company,
        email: data.email,
        twitter: data.twitter,
        linkedin: data.linkedin,
        github: data.github,
        layout: data.layout,
        body: {
          raw: body,
          code: body,
        },
      }

      authors.push(author)
    }
  }

  return authors
}

// è·å–æ‰€æœ‰æ ‡ç­¾åŠå…¶ç»Ÿè®¡
export async function getAllTags(): Promise<Record<string, number>> {
  const posts = await getAllBlogPosts()
  const tagCount: Record<string, number> = {}

  posts.forEach((post) => {
    post.tags.forEach((tag) => {
      tagCount[tag] = (tagCount[tag] || 0) + 1
    })
  })

  return tagCount
}

// æ ¹æ®æ ‡ç­¾è·å–æ–‡ç« 
export async function getPostsByTag(tag: string): Promise<BlogPost[]> {
  const posts = await getAllBlogPosts()
  return posts.filter((post) => post.tags.includes(tag))
}
